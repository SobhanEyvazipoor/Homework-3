{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading + Splitting The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of samples: 569\n",
      " Number of features: 30\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = data.feature_names\n",
    "target_names = data.target_names\n",
    "\n",
    "print(f\" Number of samples: {X.shape[0]}\")\n",
    "print(f\" Number of features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(f\" Feature names: {feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Target classes: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(f\" Target classes: {target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [212 357]\n",
      "   - malignant: 212 samples (37.3%)\n",
      "   - benign: 357 samples (62.7%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class distribution: {np.bincount(y)}\")\n",
    "print(f\"   - {target_names[0]}: {np.bincount(y)[0]} samples ({np.bincount(y)[0]/len(y)*100:.1f}%)\")\n",
    "print(f\"   - {target_names[1]}: {np.bincount(y)[1]} samples ({np.bincount(y)[1]/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 0          1          2          3          4\n",
      "mean radius                  17.99      20.57      19.69      11.42      20.29\n",
      "mean texture                 10.38      17.77      21.25      20.38      14.34\n",
      "mean perimeter               122.8      132.9      130.0      77.58      135.1\n",
      "mean area                   1001.0     1326.0     1203.0      386.1     1297.0\n",
      "mean smoothness             0.1184    0.08474     0.1096     0.1425     0.1003\n",
      "mean compactness            0.2776    0.07864     0.1599     0.2839     0.1328\n",
      "mean concavity              0.3001     0.0869     0.1974     0.2414      0.198\n",
      "mean concave points         0.1471    0.07017     0.1279     0.1052     0.1043\n",
      "mean symmetry               0.2419     0.1812     0.2069     0.2597     0.1809\n",
      "mean fractal dimension     0.07871    0.05667    0.05999    0.09744    0.05883\n",
      "radius error                 1.095     0.5435     0.7456     0.4956     0.7572\n",
      "texture error               0.9053     0.7339     0.7869      1.156     0.7813\n",
      "perimeter error              8.589      3.398      4.585      3.445      5.438\n",
      "area error                   153.4      74.08      94.03      27.23      94.44\n",
      "smoothness error          0.006399   0.005225    0.00615    0.00911    0.01149\n",
      "compactness error          0.04904    0.01308    0.04006    0.07458    0.02461\n",
      "concavity error            0.05373     0.0186    0.03832    0.05661    0.05688\n",
      "concave points error       0.01587     0.0134    0.02058    0.01867    0.01885\n",
      "symmetry error             0.03003    0.01389     0.0225    0.05963    0.01756\n",
      "fractal dimension error   0.006193   0.003532   0.004571   0.009208   0.005115\n",
      "worst radius                 25.38      24.99      23.57      14.91      22.54\n",
      "worst texture                17.33      23.41      25.53       26.5      16.67\n",
      "worst perimeter              184.6      158.8      152.5      98.87      152.2\n",
      "worst area                  2019.0     1956.0     1709.0      567.7     1575.0\n",
      "worst smoothness            0.1622     0.1238     0.1444     0.2098     0.1374\n",
      "worst compactness           0.6656     0.1866     0.4245     0.8663      0.205\n",
      "worst concavity             0.7119     0.2416     0.4504     0.6869        0.4\n",
      "worst concave points        0.2654      0.186      0.243     0.2575     0.1625\n",
      "worst symmetry              0.4601      0.275     0.3613     0.6638     0.2364\n",
      "worst fractal dimension     0.1189    0.08902    0.08758      0.173    0.07678\n",
      "target                           0          0          0          0          0\n",
      "target_name              malignant  malignant  malignant  malignant  malignant\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "df['target_name'] = df['target'].map({0: target_names[0], 1: target_names[1]})\n",
    "\n",
    "print(df.head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 569\n",
      "Training set: 398 samples (69.9%)\n",
      "Test set: 171 samples (30.1%)\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(X)\n",
    "train_samples = len(X_train)\n",
    "test_samples = len(X_test)\n",
    "\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Training set: {train_samples} samples ({train_samples/total_samples*100:.1f}%)\")\n",
    "print(f\"Test set: {test_samples} samples ({test_samples/total_samples*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution in each set:\n",
      "Training set:\n",
      "  - malignant: 148 (37.2%)\n",
      "  - benign: 250 (62.8%)\n",
      "\n",
      "Test set:\n",
      "  - malignant: 64 (37.4%)\n",
      "  - benign: 107 (62.6%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClass distribution in each set:\")\n",
    "print(\"Training set:\")\n",
    "print(f\"  - {target_names[0]}: {np.sum(y_train == 0)} ({np.sum(y_train == 0)/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  - {target_names[1]}: {np.sum(y_train == 1)} ({np.sum(y_train == 1)/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"  - {target_names[0]}: {np.sum(y_test == 0)} ({np.sum(y_test == 0)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  - {target_names[1]}: {np.sum(y_test == 1)} ({np.sum(y_test == 1)/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape after scaling: (398, 30)\n",
      "Test data shape after scaling: (171, 30)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training data shape after scaling: {X_train_scaled.shape}\")\n",
    "print(f\"Test data shape after scaling: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing CART Model + Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth:  1 - Accuracy: 0.9123\n",
      "Tree depth:  2 - Accuracy: 0.9181\n",
      "Tree depth:  3 - Accuracy: 0.9240\n",
      "Tree depth:  4 - Accuracy: 0.9240\n",
      "Tree depth:  5 - Accuracy: 0.9298\n",
      "Tree depth:  6 - Accuracy: 0.9181\n",
      "Tree depth:  7 - Accuracy: 0.9181\n",
      "Tree depth:  8 - Accuracy: 0.9181\n",
      "Tree depth:  9 - Accuracy: 0.9181\n",
      "Tree depth: 10 - Accuracy: 0.9181\n",
      "Tree depth: 11 - Accuracy: 0.9181\n",
      "Tree depth: 12 - Accuracy: 0.9181\n",
      "Tree depth: 13 - Accuracy: 0.9181\n",
      "Tree depth: 14 - Accuracy: 0.9181\n",
      "Tree depth: 15 - Accuracy: 0.9181\n",
      "Tree depth: 16 - Accuracy: 0.9181\n",
      "Tree depth: 17 - Accuracy: 0.9181\n",
      "Tree depth: 18 - Accuracy: 0.9181\n",
      "Tree depth: 19 - Accuracy: 0.9181\n",
      "Tree depth: 20 - Accuracy: 0.9181\n",
      "\n",
      "Best Decision Tree model: depth 5, accuracy 0.9298\n",
      "\n",
      "Decision Tree evaluation results on test data:\n",
      "  Accuracy:  0.9298\n",
      "  Precision: 0.9439\n",
      "  Recall:    0.9439\n",
      "  F1-score:  0.9439\n"
     ]
    }
   ],
   "source": [
    "best_dt_accuracy = 0\n",
    "best_dt_depth = 0\n",
    "best_dt_model = None\n",
    "\n",
    "for depth in range(1, 21):\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train_scaled, y_train)\n",
    "    y_pred = dt.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if accuracy > best_dt_accuracy:\n",
    "        best_dt_accuracy = accuracy\n",
    "        best_dt_depth = depth\n",
    "        best_dt_model = dt\n",
    "    \n",
    "    print(f\"Tree depth: {depth:2d} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Decision Tree model: depth {best_dt_depth}, accuracy {best_dt_accuracy:.4f}\")\n",
    "\n",
    "dt_model = best_dt_model\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "dt_precision = precision_score(y_test, y_pred_dt)\n",
    "dt_recall = recall_score(y_test, y_pred_dt)\n",
    "dt_f1 = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"\\nDecision Tree evaluation results on test data:\")\n",
    "print(f\"  Accuracy:  {dt_accuracy:.4f}\")\n",
    "print(f\"  Precision: {dt_precision:.4f}\")\n",
    "print(f\"  Recall:    {dt_recall:.4f}\")\n",
    "print(f\"  F1-score:  {dt_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Classification Report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.91      0.91      0.91        64\n",
      "      benign       0.94      0.94      0.94       107\n",
      "\n",
      "    accuracy                           0.93       171\n",
      "   macro avg       0.93      0.93      0.93       171\n",
      "weighted avg       0.93      0.93      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CART Classification Report:\")\n",
    "print(\"-\" * 30)\n",
    "print(classification_report(y_test, y_pred_dt, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Random Forest + Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees:  10 - Accuracy: 0.9298\n",
      "Number of trees:  50 - Accuracy: 0.9415\n",
      "Number of trees: 100 - Accuracy: 0.9415\n",
      "Number of trees: 150 - Accuracy: 0.9415\n",
      "Number of trees: 200 - Accuracy: 0.9415\n",
      "Number of trees: 250 - Accuracy: 0.9415\n",
      "Number of trees: 300 - Accuracy: 0.9474\n",
      "\n",
      "Best Random Forest model: 300 trees, accuracy 0.9474\n",
      "\n",
      "Random Forest evaluation results on test data:\n",
      "  Accuracy:  0.9474\n",
      "  Precision: 0.9455\n",
      "  Recall:    0.9720\n",
      "  F1-score:  0.9585\n"
     ]
    }
   ],
   "source": [
    "best_rf_accuracy = 0\n",
    "best_rf_n_estimators = 0\n",
    "best_rf_model = None\n",
    "\n",
    "n_estimators_list = [10, 50, 100, 150, 200, 250, 300]\n",
    "\n",
    "for n_estimators in n_estimators_list:\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=5, random_state=42)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    y_pred = rf.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if accuracy > best_rf_accuracy:\n",
    "        best_rf_accuracy = accuracy\n",
    "        best_rf_n_estimators = n_estimators\n",
    "        best_rf_model = rf\n",
    "    \n",
    "    print(f\"Number of trees: {n_estimators:3d} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Random Forest model: {best_rf_n_estimators} trees, accuracy {best_rf_accuracy:.4f}\")\n",
    "\n",
    "rf_model = best_rf_model\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest evaluation results on test data:\")\n",
    "print(f\"  Accuracy:  {rf_accuracy:.4f}\")\n",
    "print(f\"  Precision: {rf_precision:.4f}\")\n",
    "print(f\"  Recall:    {rf_recall:.4f}\")\n",
    "print(f\"  F1-score:  {rf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.91      0.93        64\n",
      "      benign       0.95      0.97      0.96       107\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.95      0.94      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classification Report:\")\n",
    "print(\"-\" * 30)\n",
    "print(classification_report(y_test, y_pred_rf, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
